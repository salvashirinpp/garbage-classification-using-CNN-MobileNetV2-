{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1874598,"sourceType":"datasetVersion","datasetId":1115942},{"sourceId":13969116,"sourceType":"datasetVersion","datasetId":8905201},{"sourceId":14005155,"sourceType":"datasetVersion","datasetId":8923449},{"sourceId":14005655,"sourceType":"datasetVersion","datasetId":8923788}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T07:51:31.818559Z","iopub.execute_input":"2025-12-05T07:51:31.818794Z","iopub.status.idle":"2025-12-05T07:52:04.395563Z","shell.execute_reply.started":"2025-12-05T07:51:31.818770Z","shell.execute_reply":"2025-12-05T07:52:04.394884Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"# !pip install protobuf==3.20 --quiet\n# import os\n# os.kill(os.getpid(), 9)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T07:52:04.397157Z","iopub.execute_input":"2025-12-05T07:52:04.397489Z","iopub.status.idle":"2025-12-05T07:52:04.400768Z","shell.execute_reply.started":"2025-12-05T07:52:04.397470Z","shell.execute_reply":"2025-12-05T07:52:04.400034Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport shutil\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB0 ,MobileNetV2\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.optimizers import Adam\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T07:52:04.401423Z","iopub.execute_input":"2025-12-05T07:52:04.402053Z","iopub.status.idle":"2025-12-05T07:52:21.417978Z","shell.execute_reply.started":"2025-12-05T07:52:04.402034Z","shell.execute_reply":"2025-12-05T07:52:21.417387Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"cell_type":"code","source":"base_path = \"/kaggle/input/garbage-classification/garbage_classification\"  # original data\noutput_path = \"/kaggle/working/garbage_split\"      # new split data\nclasses = os.listdir(base_path)\n\nprint(\"Classes:\", classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T07:52:21.418790Z","iopub.execute_input":"2025-12-05T07:52:21.419337Z","iopub.status.idle":"2025-12-05T07:52:21.424341Z","shell.execute_reply.started":"2025-12-05T07:52:21.419312Z","shell.execute_reply":"2025-12-05T07:52:21.423475Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Splitting into Train Test validation ","metadata":{}},{"cell_type":"code","source":"#create train test validation split\nsplits = ['train', 'val', 'test']\n\nfor split in splits:\n    for cls in classes:\n        path = os.path.join(output_path, split, cls)\n        os.makedirs(path, exist_ok=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T07:52:21.425278Z","iopub.execute_input":"2025-12-05T07:52:21.425598Z","iopub.status.idle":"2025-12-05T07:52:21.446008Z","shell.execute_reply.started":"2025-12-05T07:52:21.425569Z","shell.execute_reply":"2025-12-05T07:52:21.445428Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# split each class with 70% Train, 20% Val, 10% Test\nfor cls in classes:\n    class_path = os.path.join(base_path, cls)\n    images = os.listdir(class_path)\n\n    # Train 70%, Temporary 30%\n    train_imgs, temp_imgs = train_test_split(images, test_size=0.30, random_state=42)\n\n    # Val 20%, Test 10%\n    val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.33, random_state=42)\n\n    # -----------------------\n    # Copy Train\n    # -----------------------\n    for img in train_imgs:\n        shutil.copy(os.path.join(class_path, img),\n                    os.path.join(output_path, \"train\", cls, img))\n\n    # -----------------------\n    # Copy Validation\n    # -----------------------\n    for img in val_imgs:\n        shutil.copy(os.path.join(class_path, img),\n                    os.path.join(output_path, \"val\", cls, img))\n\n    # -----------------------\n    # Copy Test\n    # -----------------------\n    for img in test_imgs:\n        shutil.copy(os.path.join(class_path, img),\n                    os.path.join(output_path, \"test\", cls, img))\n\nprint(\"Data splitting completed!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T07:52:21.446891Z","iopub.execute_input":"2025-12-05T07:52:21.447404Z","iopub.status.idle":"2025-12-05T07:53:58.395922Z","shell.execute_reply.started":"2025-12-05T07:52:21.447385Z","shell.execute_reply":"2025-12-05T07:53:58.395135Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Create ImageDataGenerator","metadata":{}},{"cell_type":"code","source":"print(output_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T07:53:58.397834Z","iopub.execute_input":"2025-12-05T07:53:58.398090Z","iopub.status.idle":"2025-12-05T07:53:58.401967Z","shell.execute_reply.started":"2025-12-05T07:53:58.398073Z","shell.execute_reply":"2025-12-05T07:53:58.401298Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dir = \"/kaggle/working/garbage_split/train\"\nval_dir   = \"/kaggle/working/garbage_split/val\"\ntest_dir  = \"/kaggle/working/garbage_split/test\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T07:53:58.402665Z","iopub.execute_input":"2025-12-05T07:53:58.402874Z","iopub.status.idle":"2025-12-05T07:53:58.414849Z","shell.execute_reply.started":"2025-12-05T07:53:58.402849Z","shell.execute_reply":"2025-12-05T07:53:58.414281Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_size = 224\nbatch_size = 32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T07:53:58.415628Z","iopub.execute_input":"2025-12-05T07:53:58.416213Z","iopub.status.idle":"2025-12-05T07:53:58.429090Z","shell.execute_reply.started":"2025-12-05T07:53:58.416195Z","shell.execute_reply":"2025-12-05T07:53:58.428175Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_datagen=ImageDataGenerator(\n    rescale=1./255,\n    rotation_range = 40,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True\n)\n\nval_datagen  = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator= train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(image_size,image_size),\n    batch_size=batch_size,\n    class_mode='categorical')\n\nval_generator= val_datagen.flow_from_directory(\n    val_dir,\n    target_size=(image_size,image_size),\n    batch_size=batch_size,\n    class_mode='categorical'    \n)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(image_size,image_size),\n    batch_size=batch_size,\n    class_mode=None,\n    shuffle=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T07:53:58.429777Z","iopub.execute_input":"2025-12-05T07:53:58.429964Z","iopub.status.idle":"2025-12-05T07:53:58.657880Z","shell.execute_reply.started":"2025-12-05T07:53:58.429949Z","shell.execute_reply":"2025-12-05T07:53:58.657351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_generator.class_indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T07:53:58.658590Z","iopub.execute_input":"2025-12-05T07:53:58.658787Z","iopub.status.idle":"2025-12-05T07:53:58.663395Z","shell.execute_reply.started":"2025-12-05T07:53:58.658772Z","shell.execute_reply":"2025-12-05T07:53:58.662727Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Build MobileNetV2 Model","metadata":{}},{"cell_type":"code","source":"base_model = MobileNetV2(\n    weights=\"imagenet\",\n    include_top=False,\n    input_shape=(image_size,image_size,3)\n)\n\nbase_model.trainable = False  # freeze base initially\n\nx = GlobalAveragePooling2D()(base_model.output)\nx = Dropout(0.3)(x)\nx = Dense(256, activation='relu')(x)\noutputs = Dense(12, activation='softmax')(x)\n\nmodel = Model(base_model.input, outputs)\n\nmodel.compile(\n    optimizer=Adam(learning_rate=1e-3),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T07:53:58.664141Z","iopub.execute_input":"2025-12-05T07:53:58.664357Z","iopub.status.idle":"2025-12-05T07:54:01.916861Z","shell.execute_reply.started":"2025-12-05T07:53:58.664337Z","shell.execute_reply":"2025-12-05T07:54:01.916280Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\ncallbacks = [\n    EarlyStopping(patience=3, restore_best_weights=True),\n    ReduceLROnPlateau(factor=0.3, patience=2)]\n\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=5,\n    callbacks = callbacks\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T07:54:01.917589Z","iopub.execute_input":"2025-12-05T07:54:01.917860Z","iopub.status.idle":"2025-12-05T08:03:59.271432Z","shell.execute_reply.started":"2025-12-05T07:54:01.917842Z","shell.execute_reply":"2025-12-05T08:03:59.270783Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluate","metadata":{}},{"cell_type":"code","source":"#evaluate\nval_loss, val_acc = model.evaluate(val_generator)\nprint(\"Validation Accuracy:\", val_acc)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:03:59.272334Z","iopub.execute_input":"2025-12-05T08:03:59.272580Z","iopub.status.idle":"2025-12-05T08:04:03.813382Z","shell.execute_reply.started":"2025-12-05T08:03:59.272555Z","shell.execute_reply":"2025-12-05T08:04:03.812640Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualize Accuracy and Loss","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,5))\n\nplt.subplot(1,2,1)\nplt.plot(history.history['accuracy'], 'b', label='Train acc')\nplt.plot(history.history['val_accuracy'], 'r', label='Val acc')\nplt.legend(); plt.title(\"Accuracy\")\n\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'], 'b', label='Train loss')\nplt.plot(history.history['val_loss'], 'r', label='Val loss')\nplt.legend(); plt.title(\"Loss\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:04:03.814118Z","iopub.execute_input":"2025-12-05T08:04:03.814829Z","iopub.status.idle":"2025-12-05T08:04:04.159752Z","shell.execute_reply.started":"2025-12-05T08:04:03.814811Z","shell.execute_reply":"2025-12-05T08:04:04.159082Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## predict on Test image","metadata":{}},{"cell_type":"code","source":"pred = model.predict(test_generator)\nlabels = pred.argmax(axis=1)     #predicted class(label) index\nactual = test_generator.classes #actual class index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:04:04.160463Z","iopub.execute_input":"2025-12-05T08:04:04.160701Z","iopub.status.idle":"2025-12-05T08:04:12.749699Z","shell.execute_reply.started":"2025-12-05T08:04:04.160676Z","shell.execute_reply":"2025-12-05T08:04:12.749090Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save model","metadata":{}},{"cell_type":"code","source":"model.save(\"mobilenetv2_garbage_classification.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:04:12.750409Z","iopub.execute_input":"2025-12-05T08:04:12.750640Z","iopub.status.idle":"2025-12-05T08:04:13.037025Z","shell.execute_reply.started":"2025-12-05T08:04:12.750617Z","shell.execute_reply":"2025-12-05T08:04:13.036223Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Image Prediction Code","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n\n# 1. Load Your Saved Model\n\nmodel = tf.keras.models.load_model(\"mobilenetv2_garbage_classification.h5\")\n\n# List of your 12 class names (replace with your actual folder names)\nclass_names = ['battery', 'biological', 'brown-glass', 'cardboard', 'clothes',\n               'green-glass', 'metal', 'paper', 'plastic', 'shoes', 'trash', 'white-glass']\n\n\n\n\n# 2. Load and Preprocess Image\n\nimg_path = \"/kaggle/input/food-waste/food.jpg\"   # <-- replace with your test image\n\nIMG_SIZE = (224, 224)         # Same size you used in training\n\nimg = load_img(img_path, target_size=IMG_SIZE)\nimg_array = img_to_array(img) / 255.0         # normalize\nimg_array = np.expand_dims(img_array, axis=0) # add batch dim\n\n\n# 3. Predict\n\nprediction = model.predict(img_array)\npredicted_class_index = np.argmax(prediction)         # best class index\npredicted_class_name = class_names[predicted_class_index]\n\n\n# 4. Results\n\nprint(\"Raw Prediction:\", prediction)\nprint(\"Predicted Class Index:\", predicted_class_index)\nprint(\"Predicted Label:\", predicted_class_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T08:38:07.377299Z","iopub.execute_input":"2025-12-05T08:38:07.378059Z","iopub.status.idle":"2025-12-05T08:38:10.638922Z","shell.execute_reply.started":"2025-12-05T08:38:07.378024Z","shell.execute_reply":"2025-12-05T08:38:10.638344Z"}},"outputs":[],"execution_count":null}]}